{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e7471e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "max_pid = 42295 # The max number of PIDs on the Worcester Website. See 'link' below. \n",
    "pids = np.arange(1,max_pid,1) # Create Array of all the PIDs\n",
    "cols = ['pid','mblu','year','style','heat','ac','wall','roof','area'] # this is the info to extract \n",
    "\n",
    "# function to extract soup object from html document from given url\n",
    "def get_soup(pid):\n",
    "    link = \"https://gis.vgsi.com/worcesterma/Parcel.aspx?pid=\" + str(pid) # main link + pid \n",
    "    # Get Html from link\n",
    "    fp = urllib.request.urlopen(link)\n",
    "    mybytes = fp.read()\n",
    "    mystr = mybytes.decode(\"utf8\")\n",
    "  \n",
    "    # Create soup object\n",
    "    soup = BeautifulSoup(mystr, 'html.parser') \n",
    "    if soup.find(\"span\",id=\"MainContent_lblMessage\"):\n",
    "        soup = []\n",
    "    return soup\n",
    "\n",
    "# Function to retrieve MBLU from soup\n",
    "def get_mblu(soup):\n",
    "    mblue = \"\"\n",
    "    mblu = soup.find(\"span\",id=\"MainContent_lblMblu\").text.replace(\"/  \",\"-\").replace(\"/\",\"\").replace(\"\\\\\",\"-\")[:-2]\n",
    "    return mblu \n",
    "\n",
    "# Function to retrieve year from soup\n",
    "def get_year(soup):\n",
    "    year = 0\n",
    "    year = soup.find(\"span\",id=\"MainContent_ctl01_lblYearBuilt\").text\n",
    "    return year \n",
    "\n",
    "# Function to retrieve style from soup\n",
    "def get_style(soup):\n",
    "    style = \"\"\n",
    "    # Find style in html\n",
    "    style = soup.find(\"td\", text=\"Style:\").find_next_sibling(\"td\").text\n",
    "    return style\n",
    "\n",
    "# Function to retrieve style from soup\n",
    "def get_units(soup):\n",
    "    units = \"1\"\n",
    "    if soup.find(\"td\", text=\"Residential Units:\"):\n",
    "        units = soup.find(\"td\", text=\"Residential Units:\").find_next_sibling(\"td\").text\n",
    "    return units\n",
    "\n",
    "# Function to retrieve heat from soup\n",
    "def get_heat(soup):\n",
    "    heat = \"\"\n",
    "    if soup.find(\"td\", text=\"Heat Type:\"):\n",
    "        heat = soup.find(\"td\", text=\"Heat Type:\").find_next_sibling(\"td\").text\n",
    "    if soup.find(\"td\", text=\"Heat/AC\"):\n",
    "        heat = soup.find(\"td\", text=\"Heat/AC\").find_next_sibling(\"td\").text\n",
    "    return heat\n",
    "\n",
    "# Function to retrieve ac from soup\n",
    "def get_ac(soup):\n",
    "    ac = \"\"\n",
    "    if soup.find(\"td\", text='AC Type:'):\n",
    "        ac = soup.find(\"td\", text='AC Type:').find_next_sibling(\"td\").text\n",
    "    return ac\n",
    "\n",
    "# Function to retrieve wall type from soup\n",
    "def get_wall(soup):\n",
    "    wall = \"\"\n",
    "    if soup.find(\"td\", text='Exterior Wall 1'):\n",
    "        wall = soup.find(\"td\", text='Exterior Wall 1').find_next_sibling(\"td\").text\n",
    "    if soup.find(\"td\", text='Exterior Wall 1:'):\n",
    "        wall = soup.find(\"td\", text='Exterior Wall 1:').find_next_sibling(\"td\").text\n",
    "    return wall\n",
    "\n",
    "# Function to retrieve roof type from soup\n",
    "def get_roof(soup):\n",
    "    roof = \"\"\n",
    "    if soup.find(\"td\", text='Roof Cover'):\n",
    "        roof = soup.find(\"td\", text='Roof Cover').find_next_sibling(\"td\").text\n",
    "    return roof\n",
    "\n",
    "# Function to retrieve area from soup\n",
    "def get_area(soup):\n",
    "    area = 0\n",
    "    area = soup.find(\"span\",id=\"MainContent_ctl01_lblBldArea\").text.replace(\",\",\"\")\n",
    "    return area \n",
    "\n",
    "# Main function to retrieve all the data above from soup and provide DataFrame\n",
    "def main(pid):\n",
    "    soup = get_soup(pid)\n",
    "    if soup:\n",
    "        mblu = get_mblu(soup)\n",
    "        year = get_year(soup)\n",
    "        style = get_style(soup)\n",
    "        units = get_units(soup)\n",
    "        heat = get_heat(soup)\n",
    "        ac = get_ac(soup)\n",
    "        wall = get_wall(soup)\n",
    "        roof = get_roof(soup)\n",
    "        area = get_area(soup)\n",
    "        this_tax = pd.DataFrame([{'pid':pid,'mblu':mblu,'year':year,'style':style,'units':units,'heat':heat,'ac':ac,'wall':wall,'roof':roof,'area':area}])\n",
    "        return this_tax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list\n",
    "tax_list = []\n",
    "for ipid in pids:\n",
    "    # Add each individual tax dataframe to main one\n",
    "    tax_list.append(main(ipid))#pd.concat([tax,main(ipid)])\n",
    "# concat list to dataframe\n",
    "tax=pd.concat(tax_list,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0956bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b5833317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrame to CSV\n",
    "tax.to_csv('scrapped2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
